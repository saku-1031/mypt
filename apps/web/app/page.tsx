"use client";

import { useEffect, useMemo, useRef, useState, useTransition } from "react";
import { generateSpeechAction, transcribeAudioAction } from "./actions";

const DEFAULT_TTS_MODEL = "tts-1";
const DEFAULT_TTS_VOICE = "alloy";
const TTS_MODELS = [
  { value: "tts-1", label: "tts-1" },
  { value: "gpt-4o-mini-tts", label: "gpt-4o-mini-tts" },
];
const VOICE_OPTIONS = [
  { value: "alloy", label: "Alloy" },
  { value: "ash", label: "Ash" },
  { value: "coral", label: "Coral" },
  { value: "echo", label: "Echo" },
  { value: "fable", label: "Fable" },
  { value: "nova", label: "Nova" },
  { value: "onyx", label: "Onyx" },
  { value: "sage", label: "Sage" },
  { value: "shimmer", label: "Shimmer" },
];

// Capture microphone chunks every 250ms for responsive recording
const CHUNK_INTERVAL_MS = 250;

function base64ToObjectUrl(base64: string, mimeType: string): string {
  if (typeof window === "undefined") return "";
  const binary = window.atob(base64);
  const bytes = new Uint8Array(binary.length);
  for (let i = 0; i < binary.length; i++) {
    bytes[i] = binary.charCodeAt(i);
  }
  const blob = new Blob([bytes], { type: mimeType });
  return URL.createObjectURL(blob);
}

function arrayBufferToBase64(buffer: ArrayBuffer): string {
  const bytes = new Uint8Array(buffer);
  let binary = "";
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return typeof window === "undefined" ? "" : window.btoa(binary);
}

async function blobToBase64(blob: Blob): Promise<string> {
  const buffer = await blob.arrayBuffer();
  return arrayBufferToBase64(buffer);
}

export default function HomePage() {
  const [activeTab, setActiveTab] = useState<"tts" | "asr">("tts");

  const [text, setText] = useState("");
  const [voice, setVoice] = useState(DEFAULT_TTS_VOICE);
  const [model, setModel] = useState(DEFAULT_TTS_MODEL);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [ttsStatus, setTtsStatus] = useState<string | null>(null);
  const [ttsLog, setTtsLog] = useState<string | null>(null);

  const [audioFile, setAudioFile] = useState<File | null>(null);
  const [recordedUrl, setRecordedUrl] = useState<string | null>(null);
  const [asrStatus, setAsrStatus] = useState<string | null>(null);
  const [asrLog, setAsrLog] = useState<string | null>(null);
  const [transcript, setTranscript] = useState<string>("");
  const [isRecording, setIsRecording] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const [isPending, startTransition] = useTransition();
  const recordedObjectUrlRef = useRef<string | null>(null);
  const generatedAudioUrlRef = useRef<string | null>(null);

  useEffect(() => () => {
    mediaRecorderRef.current?.stream?.getTracks().forEach((track) => track.stop());
    if (generatedAudioUrlRef.current) {
      URL.revokeObjectURL(generatedAudioUrlRef.current);
      generatedAudioUrlRef.current = null;
    }
    if (recordedObjectUrlRef.current) {
      URL.revokeObjectURL(recordedObjectUrlRef.current);
      recordedObjectUrlRef.current = null;
    }
  }, []);

  const ttsDisabled = useMemo(() => !text.trim() || isPending, [text, isPending]);

  const handleGenerate = () => {
    if (!text.trim()) {
      setTtsStatus("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚");
      return;
    }

    startTransition(async () => {
      setTtsStatus("éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™â€¦");
      setTtsLog(null);

      const result = await generateSpeechAction({
        text,
        voice,
        model,
      });

      if (!result.success || !result.audioBase64) {
        setTtsStatus(result.error ?? "éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚");
        return;
      }

      if (generatedAudioUrlRef.current) {
        URL.revokeObjectURL(generatedAudioUrlRef.current);
      }

      const url = base64ToObjectUrl(result.audioBase64, result.mimeType ?? "audio/mpeg");
      generatedAudioUrlRef.current = url;
      setAudioUrl(url);
      setTtsStatus("éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚");
      setTtsLog(
        [
          `voice: ${voice}`,
          `model: ${model}`,
          `bytes: ${Math.round((result.audioBase64.length * 3) / 4)}`,
        ].join("\n")
      );
    });
  };

  const handleTranscribeFile = () => {
    if (!audioFile) {
      setAsrStatus("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚");
      return;
    }

    startTransition(async () => {
      setAsrStatus("éŸ³å£°ã‚’è§£æã—ã¦ã„ã¾ã™â€¦");
      setAsrLog(null);

      const buffer = await audioFile.arrayBuffer();
      const result = await transcribeAudioAction({
        audioBase64: arrayBufferToBase64(buffer),
        mimeType: audioFile.type || undefined,
        filenameHint: audioFile.name.replace(/[^a-zA-Z0-9_-]/g, "_") || "upload",
      });

      if (!result.success || !result.text) {
        setAsrStatus(result.error ?? "æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚");
        return;
      }

      setAsrStatus("æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚");
      setAsrLog(
        [
          `source: file`,
          `language: ${result.language ?? "unknown"}`,
          `duration: ${result.durationInSeconds ?? "-"}s`,
          `confidence: ${result.confidence !== undefined ? (result.confidence * 100).toFixed(1) + "%" : "-"}`,
        ].join("\n")
      );
      setTranscript(result.text);
      setText(result.text);
    });
  };

  const handleRecordToggle = async () => {
    if (isRecording) {
      const recorder = mediaRecorderRef.current;
      if (recorder && recorder.state !== "inactive") {
        recorder.stop();
        setAsrStatus("éŒ²éŸ³ã‚’åœæ­¢ã—ã¦ã„ã¾ã™â€¦");
      }
      return;
    }

    if (typeof navigator === "undefined" || !navigator.mediaDevices) {
      setAsrStatus("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯ãƒã‚¤ã‚¯å…¥åŠ›ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚");
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mimeType = typeof MediaRecorder !== "undefined" && MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
        ? "audio/webm;codecs=opus"
        : "audio/webm";

      const recorder = new MediaRecorder(stream, { mimeType });
      chunksRef.current = [];

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      recorder.onstop = async () => {
        stream.getTracks().forEach((track) => track.stop());
        setIsRecording(false);

        const blob = new Blob(chunksRef.current, { type: mimeType });
        chunksRef.current = [];

        if (recordedObjectUrlRef.current) {
          URL.revokeObjectURL(recordedObjectUrlRef.current);
        }
        const url = URL.createObjectURL(blob);
        recordedObjectUrlRef.current = url;
        setRecordedUrl(url);

        const base64 = await blobToBase64(blob);
        startTransition(async () => {
          setAsrStatus("éŸ³å£°ã‚’è§£æã—ã¦ã„ã¾ã™â€¦");
          setAsrLog(null);

          const result = await transcribeAudioAction({
            audioBase64: base64,
            mimeType,
            filenameHint: "recording",
          });

          if (!result.success || !result.text) {
            setAsrStatus(result.error ?? "æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚");
            return;
          }

          setAsrStatus("æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚");
          setAsrLog(
            [
              `source: microphone`,
              `language: ${result.language ?? "unknown"}`,
              `duration: ${result.durationInSeconds ?? "-"}s`,
              `confidence: ${result.confidence !== undefined ? (result.confidence * 100).toFixed(1) + "%" : "-"}`,
            ].join("\n")
          );
          setTranscript(result.text);
          setText(result.text);
        });
      };

      recorder.start(CHUNK_INTERVAL_MS);
      mediaRecorderRef.current = recorder;
      setIsRecording(true);
      setAsrStatus("éŒ²éŸ³ä¸­â€¦");
      setAsrLog(null);
      setTranscript("");
    } catch (err) {
      const message = err instanceof Error ? err.message : "ãƒã‚¤ã‚¯ã®ä½¿ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸã€‚";
      setAsrStatus(message);
    }
  };

  const resetTts = () => {
    setText("");
    setVoice(DEFAULT_TTS_VOICE);
    setModel(DEFAULT_TTS_MODEL);
    setTtsStatus(null);
    setTtsLog(null);
    if (generatedAudioUrlRef.current) {
      URL.revokeObjectURL(generatedAudioUrlRef.current);
      generatedAudioUrlRef.current = null;
    }
    setAudioUrl(null);
  };

  const resetAsr = () => {
    setAudioFile(null);
    setTranscript("");
    setAsrStatus(null);
    setAsrLog(null);
    if (recordedObjectUrlRef.current) {
      URL.revokeObjectURL(recordedObjectUrlRef.current);
      recordedObjectUrlRef.current = null;
    }
    setRecordedUrl(null);
    if (isRecording) {
      mediaRecorderRef.current?.stop();
    }
  };

  return (
    <div className="page">
      <section className="card">
        <h1>ğŸ§  Mypato Voice Console</h1>
        <p>ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ã¨éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã ã‘ã§è©¦ã›ã¾ã™ã€‚</p>
      </section>

      <div className="tabs">
        <button
          type="button"
          className={`tab ${activeTab === "tts" ? "tab-active" : ""}`}
          onClick={() => setActiveTab("tts")}
        >
          éŸ³å£°ç”Ÿæˆ (TTS)
        </button>
        <button
          type="button"
          className={`tab ${activeTab === "asr" ? "tab-active" : ""}`}
          onClick={() => setActiveTab("asr")}
        >
          æ–‡å­—èµ·ã“ã— (ASR)
        </button>
      </div>

      {activeTab === "tts" ? (
        <section className="card">
          <label htmlFor="text-input">ãƒ†ã‚­ã‚¹ãƒˆ</label>
          <textarea
            id="text-input"
            placeholder="ä¾‹: æ˜æ—¥ã®æœã«èµ·ãã‚‹æ™‚é–“ã‚’æ•™ãˆã¦ã€‚"
            value={text}
            onChange={(event) => setText(event.target.value)}
          />

          <div className="actions">
            <label>
              ãƒ¢ãƒ‡ãƒ«
              <select
                value={model}
                onChange={(event) => setModel(event.target.value)}
                className="select"
              >
                {TTS_MODELS.map((item) => (
                  <option key={item.value} value={item.value}>
                    {item.label}
                  </option>
                ))}
              </select>
            </label>

            <label>
              ãƒœã‚¤ã‚¹
              <select
                value={voice}
                onChange={(event) => setVoice(event.target.value)}
                className="select"
              >
                {VOICE_OPTIONS.map((item) => (
                  <option key={item.value} value={item.value}>
                    {item.label}
                  </option>
                ))}
              </select>
            </label>
          </div>

          <div className="actions">
            <button
              type="button"
              onClick={handleGenerate}
              className="primary-btn"
              disabled={ttsDisabled}
            >
              {isPending ? "ç”Ÿæˆä¸­â€¦" : "éŸ³å£°ã‚’ç”Ÿæˆ"}
            </button>
            <button type="button" onClick={resetTts} className="secondary-btn">
              ãƒªã‚»ãƒƒãƒˆ
            </button>
          </div>

          {ttsStatus && <p className="status">{ttsStatus}</p>}
          {ttsLog && <pre className="log">{ttsLog}</pre>}

          {audioUrl && (
            <audio className="audio-preview" controls src={audioUrl}>
              ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯ audio ã‚¿ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚
            </audio>
          )}
        </section>
      ) : (
        <section className="card">
          <label htmlFor="audio-input">éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆm4a / wav / mp4 / webmï¼‰</label>
          <input
            id="audio-input"
            className="file-input"
            type="file"
            accept="audio/*"
            onChange={(event) => setAudioFile(event.target.files?.[0] ?? null)}
          />

          <div className="actions">
            <button
              type="button"
              onClick={handleTranscribeFile}
              className="secondary-btn"
              disabled={isPending || !audioFile}
            >
              {isPending ? "è§£æä¸­â€¦" : "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—"}
            </button>
            <button type="button" onClick={resetAsr} className="secondary-btn">
              ãƒªã‚»ãƒƒãƒˆ
            </button>
          </div>

          <div className="divider" />

          <div className="actions">
            <button
              type="button"
              onClick={handleRecordToggle}
              className={`record-btn ${isRecording ? "recording" : ""}`}
              disabled={isPending}
            >
              {isRecording ? "éŒ²éŸ³åœæ­¢" : "ğŸ™ï¸ ãƒã‚¤ã‚¯ã§éŒ²éŸ³"}
            </button>
          </div>

          {recordedUrl && (
            <audio className="audio-preview" controls src={recordedUrl}>
              ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯ audio ã‚¿ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚
            </audio>
          )}

          {asrStatus && <p className="status">{asrStatus}</p>}
          {asrLog && <pre className="log">{asrLog}</pre>}
          {transcript && <pre className="transcript">{transcript}</pre>}
        </section>
      )}
    </div>
  );
}
